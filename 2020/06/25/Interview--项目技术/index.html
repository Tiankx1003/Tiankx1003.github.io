<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Interview--项目技术"><meta name="keywords" content="BigData,Interview"><meta name="author" content="Tiankx"><meta name="copyright" content="Tiankx"><title>Interview--项目技术 | Tiankx</title><link rel="shortcut icon" href="/fire.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="Tiankx" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Linux-amp-Shell"><span class="toc-text">Linux &amp; Shell</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Linux命令总结"><span class="toc-text">Linux命令总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shell工具"><span class="toc-text">Shell工具</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop"><span class="toc-text">Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#常用端口号"><span class="toc-text">常用端口号</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop配置文件和测试集群的搭建"><span class="toc-text">Hadoop配置文件和测试集群的搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS读写流程"><span class="toc-text">HDFS读写流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce的Shuffle过程"><span class="toc-text">MapReduce的Shuffle过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop优化"><span class="toc-text">Hadoop优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Yarn的Job提交流程"><span class="toc-text">Yarn的Job提交流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Yarn调度器"><span class="toc-text">Yarn调度器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LZO压缩"><span class="toc-text">LZO压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop参数调优"><span class="toc-text">Hadoop参数调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop宕机"><span class="toc-text">Hadoop宕机</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Zookeeper"><span class="toc-text">Zookeeper</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#选举机制"><span class="toc-text">选举机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#常用命令"><span class="toc-text">常用命令</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Flume"><span class="toc-text">Flume</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Flume组成，Put事务，Take事务"><span class="toc-text">Flume组成，Put事务，Take事务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flume拦截器"><span class="toc-text">Flume拦截器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flume-Channel-Selectors"><span class="toc-text">Flume Channel Selectors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flume监控器"><span class="toc-text">Flume监控器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flume采集数据会不会丢失-防止丢失数据的机制"><span class="toc-text">Flume采集数据会不会丢失 (防止丢失数据的机制)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flume内存"><span class="toc-text">Flume内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FileChannel优化"><span class="toc-text">FileChannel优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS-Sink小文件处理"><span class="toc-text">HDFS Sink小文件处理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka"><span class="toc-text">Kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka架构"><span class="toc-text">Kafka架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka概念"><span class="toc-text">Kafka概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka压测"><span class="toc-text">Kafka压测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka机器数量"><span class="toc-text">Kafka机器数量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka的日志保存时间"><span class="toc-text">kafka的日志保存时间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka的硬盘大小"><span class="toc-text">Kafka的硬盘大小</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka监控"><span class="toc-text">Kafka监控</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka分区数"><span class="toc-text">Kafka分区数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#副本数设定"><span class="toc-text">副本数设定</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Topic个数"><span class="toc-text">Topic个数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka丢不丢数据"><span class="toc-text">Kafka丢不丢数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka的ISR副本同步队列"><span class="toc-text">Kafka的ISR副本同步队列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka分区分配策略"><span class="toc-text">Kafka分区分配策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka中的数据量计算"><span class="toc-text">Kafka中的数据量计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka挂掉"><span class="toc-text">Kafka挂掉</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka数据积压怎么处理"><span class="toc-text">Kafka数据积压怎么处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka幂等性"><span class="toc-text">Kafka幂等性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka事务"><span class="toc-text">Kafka事务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka数据重复"><span class="toc-text">Kafka数据重复</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka参数优化"><span class="toc-text">Kafka参数优化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive"><span class="toc-text">Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive架构"><span class="toc-text">Hive架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive和数据库比较"><span class="toc-text">Hive和数据库比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内部表和外部表"><span class="toc-text">内部表和外部表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4个By"><span class="toc-text">4个By</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#窗口函数"><span class="toc-text">窗口函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#自定义UDF-UDAF-UDTF"><span class="toc-text">自定义UDF UDAF UDTF</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive优化"><span class="toc-text">Hive优化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HBase"><span class="toc-text">HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HBase存储结构"><span class="toc-text">HBase存储结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rowkey设计原则"><span class="toc-text">rowkey设计原则</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rowkey具体设计"><span class="toc-text">rowkey具体设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Phoenix二级索引原理"><span class="toc-text">Phoenix二级索引原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Sqoop"><span class="toc-text">Sqoop</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop任务提交参数"><span class="toc-text">Sqoop任务提交参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop导入导出Null存储一致性问题"><span class="toc-text">Sqoop导入导出Null存储一致性问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop数据导出一致性问题"><span class="toc-text">Sqoop数据导出一致性问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop底层运行的任务是什么"><span class="toc-text">Sqoop底层运行的任务是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop数据导出的时候一次执行多长时间"><span class="toc-text">Sqoop数据导出的时候一次执行多长时间</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Scala"><span class="toc-text">Scala</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark"><span class="toc-text">Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#简述spark部署方式"><span class="toc-text">简述spark部署方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark任务是使用什么提交，JavaEE界面还是脚本"><span class="toc-text">Spark任务是使用什么提交，JavaEE界面还是脚本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark作业提交参数-重点"><span class="toc-text">Spark作业提交参数(重点)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#手绘并描述Spark架构和作提交流程-重点"><span class="toc-text">手绘并描述Spark架构和作提交流程(重点)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark中血统的理解-笔试重点"><span class="toc-text">Spark中血统的理解(笔试重点)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage根据什么决定task个数"><span class="toc-text">简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage根据什么决定task个数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#列举Spark中的transformation算子并简述"><span class="toc-text">列举Spark中的transformation算子并简述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#列举Spark中的action算子并简述"><span class="toc-text">列举Spark中的action算子并简述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#列举会引起Shuffle过程的Spark算子并简述功能"><span class="toc-text">列举会引起Shuffle过程的Spark算子并简述功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#简述Spark的两种核心Shuffle-HashShuffle和SortShuffle-的工作流程-包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle-重点"><span class="toc-text">简述Spark的两种核心Shuffle(HashShuffle和SortShuffle)的工作流程(包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle)(重点)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势-重点"><span class="toc-text">Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势(重点)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Repartition和Coalesce关系和区别"><span class="toc-text">Repartition和Coalesce关系和区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#简述Spark的缓存机制，并指出区别和联系"><span class="toc-text">简述Spark的缓存机制，并指出区别和联系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#简述Spark共享变量的原理和用途"><span class="toc-text">简述Spark共享变量的原理和用途</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#简述SparkSQL中RDD-DataFrame-DataSet三者的区别与联系"><span class="toc-text">简述SparkSQL中RDD DataFrame DataSet三者的区别与联系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#当Spark涉及到数据库的操作时，如何减少运行中的数据库连接数"><span class="toc-text">当Spark涉及到数据库的操作时，如何减少运行中的数据库连接数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SparkSQL中join操作和left-join操作的区别"><span class="toc-text">SparkSQL中join操作和left join操作的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SparkStreaming有哪几种方式消费Kafka中的数据，他们之间的区别是什么"><span class="toc-text">SparkStreaming有哪几种方式消费Kafka中的数据，他们之间的区别是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#简述SparkStreaming窗口函数的原理"><span class="toc-text">简述SparkStreaming窗口函数的原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#手写WordCount的Spark实现"><span class="toc-text">手写WordCount的Spark实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#如何使用Spark实现TopN的获取-描述思路或使用伪代码"><span class="toc-text">如何使用Spark实现TopN的获取(描述思路或使用伪代码)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#调优之前和调优之后性能的详细对比"><span class="toc-text">调优之前和调优之后性能的详细对比</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark-Sql-DataFrames-DataSet"><span class="toc-text">Spark Sql, DataFrames, DataSet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#append和overwrite的区别"><span class="toc-text">append和overwrite的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cache缓存级别"><span class="toc-text">cache缓存级别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#释放缓存和缓存"><span class="toc-text">释放缓存和缓存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Shuffle默认并行度"><span class="toc-text">Spark Shuffle默认并行度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kryo序列化"><span class="toc-text">Kryo序列化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BroadCast-Join"><span class="toc-text">BroadCast Join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#控制Spark-reduce缓存-调优shuffle"><span class="toc-text">控制Spark reduce缓存 调优shuffle</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#注册UDF函数"><span class="toc-text">注册UDF函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SparkStreaming"><span class="toc-text">SparkStreaming</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Streaming第一次运行不丢失数据"><span class="toc-text">Spark Streaming第一次运行不丢失数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Streaming精准一次消费"><span class="toc-text">Spark Streaming精准一次消费</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Streaming控制每秒消费数据的速度"><span class="toc-text">Spark Streaming控制每秒消费数据的速度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Streaming背压机制"><span class="toc-text">Spark Streaming背压机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Streaming一个stage耗时"><span class="toc-text">Spark Streaming一个stage耗时</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Streaming优雅关闭"><span class="toc-text">Spark Streaming优雅关闭</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Streaming默认分区个数"><span class="toc-text">Spark Streaming默认分区个数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#元数据管理-Atlas血缘系统"><span class="toc-text">元数据管理(Atlas血缘系统)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#数据质量监控-Griffin"><span class="toc-text">数据质量监控(Griffin)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Flink"><span class="toc-text">Flink</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#应用架构"><span class="toc-text">应用架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#压测和监控"><span class="toc-text">压测和监控</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#为什么使用Flink"><span class="toc-text">为什么使用Flink</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#checkpoint的存储"><span class="toc-text">checkpoint的存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#exactly-once的保证"><span class="toc-text">exactly-once的保证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#状态机制"><span class="toc-text">状态机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#海量key去重"><span class="toc-text">海量key去重</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#checkpoint与spark的比较"><span class="toc-text">checkpoint与spark的比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#watermark机制"><span class="toc-text">watermark机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#exactly-once如何实现"><span class="toc-text">exactly-once如何实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CEP编程中，当状态没有到达的时候会将数据保存在哪里"><span class="toc-text">CEP编程中，当状态没有到达的时候会将数据保存在哪里</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#时间语义"><span class="toc-text">时间语义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据高峰的处理"><span class="toc-text">数据高峰的处理</span></a></li></ol></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/header.jpg"></div><div class="author-info__name text-center">Tiankx</div><div class="author-info__description text-center">Tiankx的个人博客</div><div class="follow-button"><a href="https://github.com/Tiankx1003" target="_blank" rel="noopener">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">20</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">7</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://molunerfinn.com" target="_blank" rel="noopener">Molunerfinn</a><a class="author-info-links__name text-center" href="https://kinomin.github.io" target="_blank" rel="noopener">KinoMin</a><a class="author-info-links__name text-center" href="https://molunerfinn.com/hexo-theme-melody-doc" target="_blank" rel="noopener">HexoMelody</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/bg.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Tiankx</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">Interview--项目技术</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-25</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="Linux-amp-Shell"><a href="#Linux-amp-Shell" class="headerlink" title="Linux &amp; Shell"></a>Linux &amp; Shell</h1><h3 id="Linux命令总结"><a href="#Linux命令总结" class="headerlink" title="Linux命令总结"></a>Linux命令总结</h3><table>
<thead>
<tr>
<th>序号</th>
<th>命令</th>
<th>命令解释</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>top</td>
<td>查看内存</td>
</tr>
<tr>
<td>2</td>
<td>df -h</td>
<td>查看磁盘存储情况</td>
</tr>
<tr>
<td>3</td>
<td>iotop</td>
<td>查看磁盘IO读写(yum install iotop安装）</td>
</tr>
<tr>
<td>4</td>
<td>iotop -o</td>
<td>直接查看比较高的磁盘读写程序</td>
</tr>
<tr>
<td>5</td>
<td>netstat -tunlp | grep 端口号</td>
<td>查看端口占用情况</td>
</tr>
<tr>
<td>6</td>
<td>uptime</td>
<td>查看报告系统运行时长及平均负载</td>
</tr>
<tr>
<td>7</td>
<td>ps   aux</td>
<td>查看进程</td>
</tr>
</tbody></table>
<h3 id="Shell工具"><a href="#Shell工具" class="headerlink" title="Shell工具"></a>Shell工具</h3><!-- TODO 添加具体使用和demo -->
<p>awk<br>sed<br>cut<br>sort</p>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h3 id="常用端口号"><a href="#常用端口号" class="headerlink" title="常用端口号"></a>常用端口号</h3><table>
<thead>
<tr>
<th align="left">Port</th>
<th align="left">Desc</th>
</tr>
</thead>
<tbody><tr>
<td align="left">50070</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">50075</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">50090</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">50010</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">9000</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">8088</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">19888</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">16010</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">8080</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">8081</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">18080</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">7180</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">5601</td>
<td align="left">-</td>
</tr>
<tr>
<td align="left">55555</td>
<td align="left">-</td>
</tr>
</tbody></table>
<h3 id="Hadoop配置文件和测试集群的搭建"><a href="#Hadoop配置文件和测试集群的搭建" class="headerlink" title="Hadoop配置文件和测试集群的搭建"></a>Hadoop配置文件和测试集群的搭建</h3><h3 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h3><!-- TODO 手绘流程图并叙述 -->


<h3 id="MapReduce的Shuffle过程"><a href="#MapReduce的Shuffle过程" class="headerlink" title="MapReduce的Shuffle过程"></a>MapReduce的Shuffle过程</h3><!-- TODO 绘图并叙述 -->

<h3 id="Hadoop优化"><a href="#Hadoop优化" class="headerlink" title="Hadoop优化"></a>Hadoop优化</h3><h3 id="Yarn的Job提交流程"><a href="#Yarn的Job提交流程" class="headerlink" title="Yarn的Job提交流程"></a>Yarn的Job提交流程</h3><h3 id="Yarn调度器"><a href="#Yarn调度器" class="headerlink" title="Yarn调度器"></a>Yarn调度器</h3><h3 id="LZO压缩"><a href="#LZO压缩" class="headerlink" title="LZO压缩"></a>LZO压缩</h3><h3 id="Hadoop参数调优"><a href="#Hadoop参数调优" class="headerlink" title="Hadoop参数调优"></a>Hadoop参数调优</h3><h3 id="Hadoop宕机"><a href="#Hadoop宕机" class="headerlink" title="Hadoop宕机"></a>Hadoop宕机</h3><h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><h3 id="选举机制"><a href="#选举机制" class="headerlink" title="选举机制"></a>选举机制</h3><p>半数机制: 2n+1<br>10台服务器: 3台<br>20台服务器: 5台<br>100台服务器: 11台</p>
<ul>
<li>台数不是越多越好，太多时选举时间过长会影响性能</li>
</ul>
<!-- TODO 添加半数机制的描述 -->

<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><p>ls  get  create</p>
<!-- TODO 添加完整命令语句 -->

<h1 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h1><h3 id="Flume组成，Put事务，Take事务"><a href="#Flume组成，Put事务，Take事务" class="headerlink" title="Flume组成，Put事务，Take事务"></a>Flume组成，Put事务，Take事务</h3><p><strong>Taildir Source</strong> 断点续传、多目录监控，Flume1.6之前需要自己自定义Source记录每次读取文件位置，实现断点续传<br><strong>File Channel</strong> 数据存储在磁盘，宕机数据可以保存，但是传输速率慢，适合对数据传输可靠性要求不高的场景，如金融<br><strong>Memory Channel</strong> 数据存储在内存中，宕机数据丢失。传输速度快，适合对数据传输可靠性不高的场景，如普通的日志数据<br><strong>Kafka Channel</strong> 减少了Flume Sink的阶段，提高了传输效率<br><strong>Put事务</strong> Source到Channel阶段<br><strong>Take事务</strong> Channel到Sink阶段</p>
<h3 id="Flume拦截器"><a href="#Flume拦截器" class="headerlink" title="Flume拦截器"></a>Flume拦截器</h3><p><strong>拦截器注意事项</strong><br>项目中自定义了:ETL拦截器和类型区分拦截器<br>采用两个拦截器优点是模块化开发和可移植性，缺点是性能会低一点</p>
<p><strong>自定义拦截器步骤</strong></p>
<ol>
<li>实现Interceptor接口</li>
<li>重写方法<code>initialize</code>初始化 <code>public Event intercept(Event event)</code>处理单个Event <code>public List&lt;Event&gt; intercept(List&lt;Event&gt; events)</code>处理多个Event，在这个方法中调用<code>Event intercept(Event event)</code> <code>close</code></li>
<li>静态内部类，实现<code>Interceptor.Builder</code></li>
</ol>
<h3 id="Flume-Channel-Selectors"><a href="#Flume-Channel-Selectors" class="headerlink" title="Flume Channel Selectors"></a>Flume Channel Selectors</h3><!-- TODO 配图 -->
<p>Channel Selectors可以让不同的项目日志通过不同的Channel到不同的Sink中去。<br>官方文档中Channel Selectors有两种类型: Replicating Channel Selector(default)和Multiplexing Channel Selector<br>这两种Selector的区别是Replicating会将source过来的events发往所有channel，而Multiplexing可以选择该发往哪些Channel</p>
<h3 id="Flume监控器"><a href="#Flume监控器" class="headerlink" title="Flume监控器"></a>Flume监控器</h3><p>Ganglia</p>
<h3 id="Flume采集数据会不会丢失-防止丢失数据的机制"><a href="#Flume采集数据会不会丢失-防止丢失数据的机制" class="headerlink" title="Flume采集数据会不会丢失 (防止丢失数据的机制)"></a>Flume采集数据会不会丢失 (防止丢失数据的机制)</h3><p>Flume采集数据不会丢失，Channel存储可以存储在File中，数据传输自身有事务</p>
<h3 id="Flume内存"><a href="#Flume内存" class="headerlink" title="Flume内存"></a>Flume内存</h3><p>开发中在flume-env.sh中设置JVM heap为4G或更高，部署在单独的服务器上(4核8线程16G内存)<br><code>-Xmx</code>与<code>-Xms</code>最好设置一致，减少内存抖动带来的性能影响，如果设置不一致容易导致频繁fullgc</p>
<h3 id="FileChannel优化"><a href="#FileChannel优化" class="headerlink" title="FileChannel优化"></a>FileChannel优化</h3><p>通过配置dataDirs指向多个路径，每个路径对应不同的硬盘，增大Flume吞吐量<br><strong><em>官方说明</em></strong><br><em>Comma separated list of directories for storing log files. Using multiple directories on separate disks can improve file channel peformance.</em></p>
<p>checkpiontDir和backupCheckpointDir也尽量配置在不容硬盘对应的目录中，保证checkpoint坏掉后，可以快速使用backupCheckpointDir恢复数据</p>
<h3 id="HDFS-Sink小文件处理"><a href="#HDFS-Sink小文件处理" class="headerlink" title="HDFS Sink小文件处理"></a>HDFS Sink小文件处理</h3><blockquote>
<p><strong>HDFS存入大量小文件的影响</strong></p>
</blockquote>
<ol>
<li><strong>元数据层面</strong> 每个小文件都有一份元数据，其中包括文件路径，文件名，所有者，所数组，权限，创建时间等，这些信息都保存在Namenode内存中，所以小文件过多，会占用Namenode服务器大量内存，影响Namenode性能和使用寿命</li>
<li><strong>计算层面</strong> 默认情况下MR会对每个小文件启用一个Map任务计算，非常影响计算性能，同时也影响磁盘寻址时间</li>
</ol>
<blockquote>
<p><strong>HDFS小文件处理</strong></p>
</blockquote>
<p>官方默认的配置三个参数会产生小文件<code>hdfs.rollInterval</code> <code>hdfs.rollSize</code> <code>hdfs.rollCount</code></p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"> <span class="attr">tmp文件创建超过3600秒时会滚动生成正式文件</span></span><br><span class="line"><span class="meta">hdfs.rollInterval</span>=<span class="string">3600</span></span><br><span class="line"> <span class="attr">tmp文件达到128M时会滚动生成正式文件</span></span><br><span class="line"><span class="meta">hdfs.rollSize</span>=<span class="string">134217728</span></span><br><span class="line"><span class="meta">hdfs.rollCount</span>=<span class="string">0</span></span><br><span class="line"><span class="meta">hdfs.roundValue</span>=<span class="string">3600</span></span><br><span class="line"><span class="meta">hdfs.roundUnit</span>=<span class="string">second</span></span><br></pre></td></tr></table></figure>
<p>如<em>2019-10-27 05:23</em>接收倒数接收到数据时会产生tmp文件<code>/demo/20191027/demo.201910270520.tmp</code><br>即使文件内容没有达到128M，也会在06:23时滚动生成正式文件</p>
<h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><h3 id="Kafka架构"><a href="#Kafka架构" class="headerlink" title="Kafka架构"></a>Kafka架构</h3><!-- TOOD 手绘Kafka架构图 -->

<h3 id="Kafka概念"><a href="#Kafka概念" class="headerlink" title="Kafka概念"></a>Kafka概念</h3><ul>
<li>AR 所有副本</li>
<li>ISR 与leader保持同步的follow集合</li>
<li>OSR 与leader未保持同步的副本集合</li>
<li>LEO 每个副本的最后一条消息的offset</li>
<li>HW 一个分区中，所有副本最小的offset</li>
</ul>
<h3 id="Kafka压测"><a href="#Kafka压测" class="headerlink" title="Kafka压测"></a>Kafka压测</h3><p>Kafka官方压测脚本kafka-consumer-pref-test.sh kafka-producer-pref-test.sh<br>使用压测可以查看系统的瓶颈出现在那个部分(CPU、内存、网络IO)，<strong>一般都是网络IO达到瓶颈</strong></p>
<h3 id="Kafka机器数量"><a href="#Kafka机器数量" class="headerlink" title="Kafka机器数量"></a>Kafka机器数量</h3><p>kafka数量 = 2 * (峰值生产速度 * 副本数 / 100) + 1</p>
<h3 id="kafka的日志保存时间"><a href="#kafka的日志保存时间" class="headerlink" title="kafka的日志保存时间"></a>kafka的日志保存时间</h3><p>七天</p>
<h3 id="Kafka的硬盘大小"><a href="#Kafka的硬盘大小" class="headerlink" title="Kafka的硬盘大小"></a>Kafka的硬盘大小</h3><p>每天的数据量 * 7天</p>
<h3 id="Kafka监控"><a href="#Kafka监控" class="headerlink" title="Kafka监控"></a>Kafka监控</h3><p>公司自己开发的监控器<br>开源的监控器: KafkaManager、KafkaMonitor</p>
<h3 id="Kafka分区数"><a href="#Kafka分区数" class="headerlink" title="Kafka分区数"></a>Kafka分区数</h3><p>分区数并不是越多越好，一般分区数不要超过集群机器数量，分区数越多占用内存越大(ISR等)，一个节点集中的分区也就越多，当它宕机的时候，对系统的影响也就越大<br>分区数一般设置为3-10个</p>
<h3 id="副本数设定"><a href="#副本数设定" class="headerlink" title="副本数设定"></a>副本数设定</h3><p>一般设置成2或3个，大部分企业设置为2个</p>
<h3 id="Topic个数"><a href="#Topic个数" class="headerlink" title="Topic个数"></a>Topic个数</h3><p>通常情况下，多少个日志类型就用多少个Topic，也有对日志类型进行合并的</p>
<h3 id="Kafka丢不丢数据"><a href="#Kafka丢不丢数据" class="headerlink" title="Kafka丢不丢数据"></a>Kafka丢不丢数据</h3><p><strong>Ack=0</strong> 相当于异步发送，消息发送完毕即offset增加，继续生产<br><strong>Ack=1</strong> leader收到leader replica对一个消息的接收ack才增加offset，然后继续生产<br><strong>Ack=-1</strong> leader收到所有的replica对一个消息的接收ack才增加offset，然后继续生产</p>
<ul>
<li>当ack设置成-1时是不会丢失数据的</li>
</ul>
<!-- TOOD kafka丢不丢数据 -->

<h3 id="Kafka的ISR副本同步队列"><a href="#Kafka的ISR副本同步队列" class="headerlink" title="Kafka的ISR副本同步队列"></a>Kafka的ISR副本同步队列</h3><p>ISR(In-Sync Replicas) 副本同步队列。ISR中包括Leader和Follower，如果Leader进程挂掉，会在ISR队列中选择一个服务作为新的Leader，有replica.lag.max.messages(延迟条数)和replica.lag.time.max.ms(延迟时间)两个参数决定一台服务器是否可以加入ISR副本队列，在0.10版本移除了replica.lag.max.messages参数，防止服务频繁的进入队列。<br>任意一个维度超过阈值都会把Follower剔除出ISR，存入OSR(Outof-Sync Replicas)列表，新加入的Follower也会存放在OSR中。</p>
<h3 id="Kafka分区分配策略"><a href="#Kafka分区分配策略" class="headerlink" title="Kafka分区分配策略"></a>Kafka分区分配策略</h3><p>Kafka内部存在两种默认的分区分配策略:<strong>Range</strong>和<strong>RoundRobin</strong></p>
<blockquote>
<p><strong>Range策略</strong></p>
</blockquote>
<p>是kafka的默认分区分配策略，是对每个topic而言(即一个topic一个topic分)。<br>首先对同一个topic里面的分区按照序列号进行排序，并对消费者按照字母顺序进行排序，然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前几个消费者线程将会多消费一个分区</p>
<blockquote>
<p><strong>RoundRobin</strong></p>
</blockquote>
<p>前提是同一个ConsumerGroup里面的所有消费者的num.streams(消费者线程数)必须相等，每个消费者订阅的主题必须相同<br>将所有主题分区组成TopicAndPartition列表，然后对TopicAndPartition列表按照hashCode进行排序，最后按照轮询的方式发给每一个消费线程</p>
<h3 id="Kafka中的数据量计算"><a href="#Kafka中的数据量计算" class="headerlink" title="Kafka中的数据量计算"></a>Kafka中的数据量计算</h3><p>每天的总数据量100g，每天产生1亿条日志，10000万/24/60/60=1150条/秒<br>平均每秒钟1150条<br>低谷每秒钟400条<br>高峰每秒钟1150条*(2 ~ 20倍)=2300条 ~ 23000条<br>每条日志大小0.5k ~ 2k<br>每秒数据量2.3MB ~20MB</p>
<h3 id="Kafka挂掉"><a href="#Kafka挂掉" class="headerlink" title="Kafka挂掉"></a>Kafka挂掉</h3><p>Flume记录 <!-- 使用Flume恢复Kafka数据 --><br>Kafka日志 <!-- kafka日志和原始数据的格式不同 --><br>Kafka中日志保存时间为7天，短期内没事</p>
<h3 id="Kafka数据积压怎么处理"><a href="#Kafka数据积压怎么处理" class="headerlink" title="Kafka数据积压怎么处理"></a>Kafka数据积压怎么处理</h3><ul>
<li>如果是kafka消费能力不足，可以同时增加topic的分区数和消费者组的消费者数量来提升(注:保证<strong>消费者数=分区数</strong>)</li>
<li>如果是下游的数据处理不及时，可以提高没批次拉取的数量。批次拉取数据过好(拉取数据/处理事件&lt;生产速度)，导致处理的数据小于生产的数据，也会造成数据积压</li>
</ul>
<h3 id="Kafka幂等性"><a href="#Kafka幂等性" class="headerlink" title="Kafka幂等性"></a>Kafka幂等性</h3><p>Producer的幂等性指的是当发送一条消息时，数据在Server端只会被持久化一次，数据不丢且不重。<br>但是这里的幂等性是有条件的:</p>
<ul>
<li>只能保证Producer在单个会话内不丢不重，如果Producer出现意外挂掉再重启是无法保证的(幂等性情况下，是无法获取之前的状态信息的，因此无法做到跨会话级别的不丢不重)</li>
<li>幂等性不能跨多个Topic-Partition，只能单个Partition内的幂等性，当涉及多个Topic-Partition时，这中间的状态并没有同步<br><strong>数据不丢，但是有可能数据重复</strong></li>
</ul>
<h3 id="Kafka事务"><a href="#Kafka事务" class="headerlink" title="Kafka事务"></a>Kafka事务</h3><p>Kafka从0.11版本开始引入了事务支持，事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<ol>
<li>Produce事务<br>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定，这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID<br>为了管理Transction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</li>
<li>Consumer事务<br>上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其是无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况</li>
</ol>
<h3 id="Kafka数据重复"><a href="#Kafka数据重复" class="headerlink" title="Kafka数据重复"></a>Kafka数据重复</h3><p>Kafka数据重复，可以在下一级SparkStreaming、redis、或hive中dwd层去重<br>去重的手段:分组、按照id开窗只取第一个值</p>
<h3 id="Kafka参数优化"><a href="#Kafka参数优化" class="headerlink" title="Kafka参数优化"></a>Kafka参数优化</h3><blockquote>
<p><strong>Brokercan参数设置(server.properties)</strong></p>
</blockquote>
<ol>
<li>网络和io操作线程配置优化</li>
</ol>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"> <span class="attr">broker处理消息的最大线程数(默认为3)</span></span><br><span class="line"><span class="meta">num.network.threads</span>=<span class="string">cpu核心数+1</span></span><br><span class="line"> <span class="attr">broker处理磁盘io的线程数</span></span><br><span class="line"><span class="meta">num.io.threads</span>=<span class="string">cpu核心数*2</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>log数据文件刷盘策略</li>
</ol>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"> <span class="attr">producer每写入10000条数据时，刷新数据到磁盘</span></span><br><span class="line"><span class="meta">log.flush.interval.messages</span>=<span class="string">1000</span></span><br><span class="line"> <span class="attr">每间隔1秒钟刷数据到磁盘</span></span><br><span class="line"><span class="meta">log.flush.interval.ms</span>=<span class="string">1000</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>日志保留策略配置</li>
</ol>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"> <span class="attr">保留三天或者更短(log.clear.delete.retention.ms)</span></span><br><span class="line"><span class="meta">log.retention.hours</span>=<span class="string">72</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Replica相关配置</li>
</ol>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"> <span class="meta">新创建一个topic时，默认的Replica数量，Replica过少会影响数据的可用性，太多则会白白浪费存储资源，一般建议2</span> <span class="string">~ 3为宜</span></span><br><span class="line"><span class="meta">offsets.topic.replication.factor</span>=<span class="string">3</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>Producer优化(producer.properties)</strong></p>
</blockquote>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"> <span class="attr">在producer端用来存放尚未发出去的Message的缓冲区大小，缓冲区满了之后可以选择阻塞发送或抛出异常，由block.on.buffer.full的配置决定</span></span><br><span class="line"><span class="meta">buffer.memory</span>=<span class="string">335544323 (32MB)</span></span><br><span class="line"> <span class="attr">默认发送不进行压缩，推荐配置一种适合的压缩算法，可以大幅度的减缓网络压力和Broker的存储压力</span></span><br><span class="line"><span class="meta">compression.type</span>=<span class="string">none</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>Consumer优化</strong></p>
</blockquote>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"> <span class="attr">启动consumer的个数，适当增加可以提高的并发度</span></span><br><span class="line"><span class="meta">num.consumer.fetchers</span>=<span class="string">1</span></span><br><span class="line"> <span class="meta">每次fetch</span> <span class="string">request至少拿到多少字节的数据才可以返回</span></span><br><span class="line"><span class="meta">fetch.min.bytes</span>=<span class="string">1</span></span><br><span class="line"> <span class="meta">在fetch</span> <span class="string">request获取的数据至少到达fetch.min.bytes之前，允许等待的最大时长，对应上面硕大欧帝尔Purgatory中请求的超时时间</span></span><br><span class="line"><span class="meta">fetch.wait.max.ms</span>=<span class="string">100</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>Kafka内存调整(kafka-server-start.sh</strong></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> 默认内存1个G，生产环境经历爱情不要超过6G</span><br><span class="line">export KAFKA_HEAP_OPTS="-Xms4g -Xmx4g"</span><br></pre></td></tr></table></figure>

<h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h3 id="Hive架构"><a href="#Hive架构" class="headerlink" title="Hive架构"></a>Hive架构</h3><h3 id="Hive和数据库比较"><a href="#Hive和数据库比较" class="headerlink" title="Hive和数据库比较"></a>Hive和数据库比较</h3><ol>
<li>数据存储位置不同<br> Hive存储在HDFS，数据库将数据保存在块设备或者本地文件系统中</li>
<li>数据更新<br> Hive不建议对数据改写，而数据库中的数据通常是需要经常进行修改的</li>
<li>执行延迟<br> Hive执行延迟较高，数据库的执行延迟低，但是数据库的数据规模也较小，当数据的规模超过数据库的处理能力时，Hive的并行计算显然能体现出优势</li>
<li>数据规模<br> Hive支持很大规模的数据计算，数据库可以支持的数据规模较小</li>
</ol>
<h3 id="内部表和外部表"><a href="#内部表和外部表" class="headerlink" title="内部表和外部表"></a>内部表和外部表</h3><p><strong>管理表</strong> 当删除一个管理表时，Hive也会删除表对应的数据，管理表不适合和其他工具共享数据<br><strong>外部表</strong> 删除该表并不会删除掉原始数据，删除的是表的元数据</p>
<h3 id="4个By"><a href="#4个By" class="headerlink" title="4个By"></a>4个By</h3><p><strong>Sort By</strong> 分区内有序<br><strong>Order By</strong> 全局排序，只有一个Reducer<br><strong>Distribute By</strong> 类似MR中Partition，进行分区，结合sort by使用<br><strong>Cluster By</strong> 当Distribute by和Sort by字段相同时，可以使用Cluster by代替。Cluster by兼具Distribute by和Sort by的功能，但是排序只能是升序排序，不能指定排序规则ASC或者DESC</p>
<h3 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h3><p><strong><em>RANK()</em></strong> 排序，相同时会重复，总数不会变<br><strong><em>DENSE_RANK()</em></strong> 排序相同时会重复，总数会减少<br><strong><em>ROW_NUMBER()</em></strong> 会根据顺序计算<br><code>OVER()</code> 指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化<br><code>CURRENT ROW</code> 当前行<br><code>n PRECEDING</code> 往前n行数据<br><code>n FOLLOWING</code> 往后n行数据<br><code>UNBOUNDED</code> 起点，<code>UNBOUNDED PRECEDING</code>表示从前面的起点，<code>UNBOUNDED FOLLOWING</code>表示到后面的终点<br><code>LAG(col,n)</code> 往前第n行数据<br><code>LEAD(col,n)</code> 往后第n行数据<br><code>NTILE(n)</code> 把有序分区中的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，NTILE返回慈航所属的组的编号，注意:n必须为int类型</p>
<h3 id="自定义UDF-UDAF-UDTF"><a href="#自定义UDF-UDAF-UDTF" class="headerlink" title="自定义UDF UDAF UDTF"></a>自定义UDF UDAF UDTF</h3><p><strong>UDF</strong> 继承UDF重写evaluate方法<br><strong>UDTF</strong> 继承自GenericUDTF，重写3个方法，initialize(自定义输出的列名和类型) process(将结果返回forward(result)) close<br>自定义UDF/UDTF用于自己埋点Log打印日志，出错或者数据异常，方便调试</p>
<h3 id="Hive优化"><a href="#Hive优化" class="headerlink" title="Hive优化"></a>Hive优化</h3><p><strong>MapJoin</strong><br>如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即在Reduce阶段完成Join，容易发生数据倾斜。可以使用MapJoin把小表全部加载到内存Map端执行Join，避免reduce处理<br><strong>行列过滤</strong><br>列处理: 在SELECT中，只拿需要的列，如果有，尽量使用分区过滤，少用SELECT *<br>行处理: 在分区裁剪中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，然后再过滤<br><strong>采用分桶技术</strong><br><strong>采用分区技术</strong><br><strong>合理设置Map数</strong><br>通常情况下，作业会通过input的目录产生一个或者多个map任务，主要的决定因素有:input的文件总个数，input的文件大小，集群设置的文件块大小；<br>map数并不是越多越好，如果一个任务有很多小文件(远远小于块大小128m)，则每个小文件也会被当作一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费，而且同时可执行的map数都是受限的。这种情形一般通过减少map数来解决；<br>并不是每个map处理接近128m的文件块就能解决所有问题，如果一个127m的文件，正常会用一个map完成，但是如果这个文件只有一个或者两个小字段，却有几千万条记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定效率很低。发生这种情况就需要增加map数。<br><strong>小文件进行合并</strong><br>在map执行前合并小文件，减少map数，CombineHiveInputFormat具有对文件进行合并的功能(系统默认的格式)，HiveInputFormat没有对小文件合并功能<br><strong>合理设置Reduce数</strong><br>Reduce个数并不是越多越好。过多的启动和初始化Reduce也会消耗时间和资源，另外有多少个Reduce就会有多少输出文件，如果生成了很多小文件，那么如果这些小文件作为下一个任务的输入，则会出现小文件过多的问题。<br><strong>常用参数</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 输出合并小文件</span></span><br><span class="line"><span class="keyword">SET</span> hive.merge.mapfiles=<span class="literal">true</span>; <span class="comment">--默认true，在map-only任务结束时合并小文件</span></span><br><span class="line"><span class="keyword">SET</span> hive.merge.mapredfiles=<span class="literal">true</span>; <span class="comment">--默认false，在map-reduce任务结束时合并小文件</span></span><br><span class="line"><span class="keyword">SET</span> hive.merge.size.per.task=<span class="number">268435456</span>; <span class="comment">--默认256</span></span><br><span class="line"><span class="keyword">SET</span> hive.merge.smallfiles.avgsize=<span class="number">16777216</span>; <span class="comment">--当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行小文件merge</span></span><br></pre></td></tr></table></figure>

<h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h3 id="HBase存储结构"><a href="#HBase存储结构" class="headerlink" title="HBase存储结构"></a>HBase存储结构</h3><!-- TODO 配图 -->

<h3 id="rowkey设计原则"><a href="#rowkey设计原则" class="headerlink" title="rowkey设计原则"></a>rowkey设计原则</h3><ol>
<li>rowkey长度原则</li>
<li>rowkey散列原则</li>
<li>rowkey唯一原则</li>
</ol>
<!-- TODO 添加具体原则 -->

<h3 id="rowkey具体设计"><a href="#rowkey具体设计" class="headerlink" title="rowkey具体设计"></a>rowkey具体设计</h3><ol>
<li>生成随机数、Hash、散列值</li>
<li>字符串反转</li>
</ol>
<h3 id="Phoenix二级索引原理"><a href="#Phoenix二级索引原理" class="headerlink" title="Phoenix二级索引原理"></a>Phoenix二级索引原理</h3><!-- TODO 详述原理 -->

<h1 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h1><h3 id="Sqoop任务提交参数"><a href="#Sqoop任务提交参数" class="headerlink" title="Sqoop任务提交参数"></a>Sqoop任务提交参数</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--count \</span><br><span class="line">--username \</span><br><span class="line">--password \</span><br><span class="line">--target-dir \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--num-mappers \</span><br><span class="line">--fields-terminated-by \</span><br><span class="line">--query <span class="string">"<span class="variable">$2</span>"</span> <span class="string">'and $CONDITIONS;'</span></span><br></pre></td></tr></table></figure>

<h3 id="Sqoop导入导出Null存储一致性问题"><a href="#Sqoop导入导出Null存储一致性问题" class="headerlink" title="Sqoop导入导出Null存储一致性问题"></a>Sqoop导入导出Null存储一致性问题</h3><p>Hive中的Null在底层是以<code>\N</code>来存储，而MySQL中的Null的底层就是Null，为了保证数据两端的一致性。在导出数据时采用<code>--input-null-string</code>和<code>--input-null-non-string</code>两个参数。导入时采用<code>--null-string</code>和<code>--null-non-string</code></p>
<h3 id="Sqoop数据导出一致性问题"><a href="#Sqoop数据导出一致性问题" class="headerlink" title="Sqoop数据导出一致性问题"></a>Sqoop数据导出一致性问题</h3><ol>
<li>场景一: 如Sqoop在导出到MySQL时，使用4个Map任务，过程中有2个任务失败，那此时MySQL中存储了另外两个Map任务导入的数据，此时老板正好看到这个报表数据。而开发工程师发现任务失败后，会调试问题并最终将全部数据正确的导入MySQL，那后面老板再次看报表数据，发现本次看到的数据和之前的不一致，这在生产环境是不允许的。<br>参考官网描述 <a href="http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html" target="_blank" rel="noopener">http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html</a></li>
</ol>
<p><em>Since Sqoop breaks down export process into multiple transactions, it is possible that a failed export job may result in partial data being committed to the database. This can further lead to subsequent jobs failing due to insert collisions in some cases, or lead to duplicated data in others. You can overcome this problem by specifying a staging table via the –staging-table option which acts as an auxiliary table that is used to stage exported data. The staged data is finally moved to the destination table in a single transaction.</em><br>-staging-table方式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> --connect jdbc:mysql://192.168.137.10:3306/user_behavior \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table app_cource_study_report \</span><br><span class="line">--columns watch_video_cnt,complete_video_cnt,dt \</span><br><span class="line">--fields-terminated-by <span class="string">"\t"</span> \</span><br><span class="line">--<span class="built_in">export</span>-dir <span class="string">"/user/hive/warehouse/tmp.db/app_cource_study_analysis_<span class="variable">$&#123;day&#125;</span>"</span> \</span><br><span class="line">--staging-table app_cource_study_report_tmp \</span><br><span class="line">--clear-staging-table \</span><br><span class="line">--input-null-string <span class="string">'\N'</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>场景2: 设置map数量为1个(不推荐，面试官想要的答案不只是这个)，多个map任务时，采用-staging-table方式，任然可以解决数据一致性问题</li>
</ol>
<h3 id="Sqoop底层运行的任务是什么"><a href="#Sqoop底层运行的任务是什么" class="headerlink" title="Sqoop底层运行的任务是什么"></a>Sqoop底层运行的任务是什么</h3><p>只有Map阶段，没有Reduce阶段的任务，默认开启4个MR</p>
<h3 id="Sqoop数据导出的时候一次执行多长时间"><a href="#Sqoop数据导出的时候一次执行多长时间" class="headerlink" title="Sqoop数据导出的时候一次执行多长时间"></a>Sqoop数据导出的时候一次执行多长时间</h3><p>Sqoop任务5分钟~2小时的都有，取决于数量</p>
<h1 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h1><h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h3 id="简述spark部署方式"><a href="#简述spark部署方式" class="headerlink" title="简述spark部署方式"></a>简述spark部署方式</h3><p>local: 运行在一台机器上，通常用于测试<br>Standalone: 构建要给基于Master+Slaves的资源调度集群，Spark任务提交给Master运行，是Spark自身的一个调度系统<br>Yarn: Spark客户端直接连接Yarn，不需要额外构建Spark集群，有yarn-client和yarn-cluster两种模式，主要区别在于，Driver程序的运行节点<br>Mesos: 国内使用较少</p>
<h3 id="Spark任务是使用什么提交，JavaEE界面还是脚本"><a href="#Spark任务是使用什么提交，JavaEE界面还是脚本" class="headerlink" title="Spark任务是使用什么提交，JavaEE界面还是脚本"></a>Spark任务是使用什么提交，JavaEE界面还是脚本</h3><p>Shell脚本</p>
<h3 id="Spark作业提交参数-重点"><a href="#Spark作业提交参数-重点" class="headerlink" title="Spark作业提交参数(重点)"></a>Spark作业提交参数(重点)</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">spark-submit \</span><br><span class="line">--master <span class="built_in">local</span>[5]  \</span><br><span class="line">--driver-cores 2   \</span><br><span class="line">--driver-memory 8g \</span><br><span class="line">--executor-cores 4 \</span><br><span class="line">--num-executors 10 \</span><br><span class="line">--executor-memory 8g \</span><br><span class="line">--class PackageName.ClassName XXXX.jar \</span><br><span class="line">--name <span class="string">"Spark Job Name"</span> \</span><br><span class="line">InputPath      \</span><br><span class="line">OutputPath</span><br></pre></td></tr></table></figure>
<p><code>--executor-cores</code> 每个executor使用的内核数，默认为1，官方建议2-5个，我们企业使用4个<br><code>--num-executors</code> 启动executor的数量，默认为2<br><code>--executor-memory</code> executor的内存大小，默认为1g<br><code>--driver-cores</code> driver使用内核数，默认为1<br><code>--driver-memory</code> driver内存大小，默认为512M</p>
<h3 id="手绘并描述Spark架构和作提交流程-重点"><a href="#手绘并描述Spark架构和作提交流程-重点" class="headerlink" title="手绘并描述Spark架构和作提交流程(重点)"></a>手绘并描述Spark架构和作提交流程(重点)</h3><!-- TODO 添加配图 -->

<h3 id="Spark中血统的理解-笔试重点"><a href="#Spark中血统的理解-笔试重点" class="headerlink" title="Spark中血统的理解(笔试重点)"></a>Spark中血统的理解(笔试重点)</h3><p>RDD在Lineage依赖方面分为两种Narrow Dependencies与Wide Dependencies用来解决数据容错时的高效性以及划分任务时候起到作用</p>
<h3 id="简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage根据什么决定task个数"><a href="#简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage根据什么决定task个数" class="headerlink" title="简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage根据什么决定task个数"></a>简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage根据什么决定task个数</h3><p>根据RDD之间的依赖关系不同将job划分成不同的stage，遇到一个宽依赖则划分一个stage<br>stage是一个TaskSet，将Stage根据分区数划分成一个个的Task</p>
<!-- TODO 待补充 -->
<p>由于 Spark 的懒执行, 在驱动程序调用一个action之前, Spark 应用不会做任何事情.<br><strong>针对每个 action, Spark 调度器就创建一个执行图(execution graph)和启动一个 Spark job</strong><br>每个 job 由多个stages 组成, 这些 stages 就是实现最终的 RDD 所需的数据转换的步骤. 一个宽依赖划分一个 stage.<br>每个 stage 由多个 tasks 来组成, 这些 tasks 就表示每个并行计算, 并且会在多个执行器上执行.</p>
<h3 id="列举Spark中的transformation算子并简述"><a href="#列举Spark中的transformation算子并简述" class="headerlink" title="列举Spark中的transformation算子并简述"></a>列举Spark中的transformation算子并简述</h3><ul>
<li><code>map(func)</code> 按照func对RDD中的每个元素进行转换得到新的RDD，用于改变RDD的数据结构类型</li>
<li><code>mapPartitions(func)</code> 类似于map，但独立地在RDD的每一个分片上运行，<code>Iterator[T] =&gt; Iterator[U]</code>，每个分区执行一次func操作</li>
<li><code>mapPartitionsWithIndex(func)</code> 和mapPartitions(func)类似. 但是会给func多提供一个Int值来表示分区的索引</li>
<li><code>flatMap(fun)</code> 类似于map，但是每一个输入元素可以被映射为0或多个输出元素，func返回一个序列</li>
<li><code>glom()</code> 将每一个分区的元素合并成一个数组，形成新的 RDD 类型是<code>RDD[Array[T]]</code></li>
<li><code>groupBy(func)</code> 按照func的返回值进行分组</li>
<li><code>filter(func)</code> 过滤，返回func返回值为true的元素组成的RDD</li>
<li><code>coalesce(numPartitions)</code> 缩减分区数到指定数量</li>
<li><code>repartition(numPartitions)</code> 根据新的分区数重新shuffle数据，分区数可以增多或减少</li>
<li><code>reduceByKey(func, [numTask])</code> 在一个(K, V)的RDD上调用，返回一个(K, V)的RDD，使用reduce函数，将相同key的值聚合到一起，reduce任务的个数可以通过第二个可选的参数来设置</li>
<li><code>aggregateByKey(zeroValue:U,[partition:Partitioner])(seqOp:(U,V)=&gt;U,combOp:(U,U)=&gt;U)</code> 在kv对的RDD中，按key将value进行分组合并，合并时，将每个value和初始值作为seq函数的参数，进行计算，返回的结果作为一个新的kv对，然后再将结果按照key进行合并，最后将每个分组的value传递给combine函数进行计算(先将前两个value进行计算)，将返回结果和下一个value传给combine函数，以此类推)，将key与计算结果作为一个新的kv输出。</li>
<li><code>combineByKey(createCombiner:V=&gt;C, mergeValue:(C,V)=&gt;C,mergeCombiners:(C,C)=&gt;C)</code> 对相同K，把V合并成一个集合</li>
</ul>
<h3 id="列举Spark中的action算子并简述"><a href="#列举Spark中的action算子并简述" class="headerlink" title="列举Spark中的action算子并简述"></a>列举Spark中的action算子并简述</h3><ul>
<li><code>reduce(func)</code> 通过func函数聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据</li>
<li><code>collect</code> 以数组的形式返回RDD中的所有元素，所有的的数据都会被拉到driver端，慎用(OOM)</li>
<li><code>first</code> 返回RDD中的第一个元素</li>
<li><code>take(n)</code> 返回RDD中前n个元素组成的数组</li>
<li><code>count</code> 返回RDD中元素的个数</li>
<li><code>foreach(func)</code> 对每个RDD执行一次func</li>
<li><code>aggregate[U: ClassTag](zeroValue: U)(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U)</code> aggregate函数将每个分区里面的元素通过seqOp和初始值进行聚合，然后用combine函数将每个分区的结果和初始值(zeroValue)进行combine操作。这个函数最终返回的类型不需要和RDD中元素类型一致，zeroValue会在分区内聚合和分区间聚合各使用一次</li>
<li><code>fold</code> 折叠操作，aggregate的简化操作，seqop和combop一样的时候，可使用fold</li>
<li><code>countByKey()</code>针对(K,V)类型的 RDD，返回一个(K,Int)的map，表示每一个key对应的元素个数，用于查看数据是否倾斜</li>
<li><code>saveAsTextFile(path)</code> 将数据集的元素以textfile的形式保存到指定文件系统</li>
<li><code>saveAsSequenceFile(path)</code> 将数据集的元素以Hadoop sequenceFile的形式保存到Hadoop支持的文件系统</li>
</ul>
<h3 id="列举会引起Shuffle过程的Spark算子并简述功能"><a href="#列举会引起Shuffle过程的Spark算子并简述功能" class="headerlink" title="列举会引起Shuffle过程的Spark算子并简述功能"></a>列举会引起Shuffle过程的Spark算子并简述功能</h3><h3 id="简述Spark的两种核心Shuffle-HashShuffle和SortShuffle-的工作流程-包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle-重点"><a href="#简述Spark的两种核心Shuffle-HashShuffle和SortShuffle-的工作流程-包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle-重点" class="headerlink" title="简述Spark的两种核心Shuffle(HashShuffle和SortShuffle)的工作流程(包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle)(重点)"></a>简述Spark的两种核心Shuffle(HashShuffle和SortShuffle)的工作流程(包括未优化的HashShuffle、优化的HashShuffle、普通的SortShuffle与bypass的SortShuffle)(重点)</h3><!-- TODO 绘图描述 -->


<h3 id="Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势-重点"><a href="#Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势-重点" class="headerlink" title="Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势(重点)"></a>Spark常用算子reduceByKey与groupByKey的区别，哪一种更具优势(重点)</h3><p>reduceByKey按照key进行聚合，在shuffle之前有combine(预聚合)操作，返回结果是<code>RDD[K,V]</code><br>groupByKey按照key进行分组，直接进行shuffle<br>在不影响业务逻辑的情况下，推荐使用reduceByKey</p>
<h3 id="Repartition和Coalesce关系和区别"><a href="#Repartition和Coalesce关系和区别" class="headerlink" title="Repartition和Coalesce关系和区别"></a>Repartition和Coalesce关系和区别</h3><p><strong>关系</strong><br>两者都是用来改变RDD的partition数量的，repartition底层调用的就是coalesce方法</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">coalesce(numPartitions, shuffle=<span class="literal">true</span>)</span><br></pre></td></tr></table></figure>
<p><strong>区别</strong><br>repartition一定会发生shuffle，coalesce根据传入参数来判断是否发生shuffle<br>一般情况下增大rdd的partition数量使用repartition，减少partition数量使用coalesce</p>
<h3 id="简述Spark的缓存机制，并指出区别和联系"><a href="#简述Spark的缓存机制，并指出区别和联系" class="headerlink" title="简述Spark的缓存机制，并指出区别和联系"></a>简述Spark的缓存机制，并指出区别和联系</h3><p>都是RDD持久化<br>cache内存，不会截断血缘关系，使用计算过程中的数据缓存<br>checkpoint，磁盘，截断血缘关系，在ck之前必须没有任何任务提交才会失效，ck过程会提交一次任务</p>
<h3 id="简述Spark共享变量的原理和用途"><a href="#简述Spark共享变量的原理和用途" class="headerlink" title="简述Spark共享变量的原理和用途"></a>简述Spark共享变量的原理和用途</h3><ul>
<li><p>累加器(accumulator)是spark中提供的一种分布式的变量机制，其原理类似于mapreduce，即分布式的改变，然后聚合这些改变</p>
</li>
<li><p>累加器主要用于累加计数性质，广播变量主要用于高效的分发较大的对象</p>
</li>
<li><p>Spark中在做map或者filter时，executor都会用到driver中的变量，而每个节点上操作这些变量不会真正改变driver中的值</p>
</li>
<li><p>累加器和广播变量主要用于结果聚合和广播这两种通信模式</p>
<p> <strong>累加器</strong></p>
</li>
<li><p>分布式运行，driver发给executor的是变量的值，在executor运算和driver的值无关</p>
</li>
<li><p>累加器实现了共享变量的修改</p>
</li>
<li><p>累加器只在行动算子中使用，不在转换算子中使用</p>
<p> <strong>广播变量</strong></p>
</li>
<li><p>当driver传递给executor变量只用于读取时</p>
</li>
<li><p>同一个进程的每一个task线程都有一个变量，数据冗余，占用内存</p>
</li>
<li><p>广播变量不直接发给每个task线程，而是直接发到executor，task线程共享变量</p>
</li>
<li><p>极大的优化了内存的占用</p>
</li>
</ul>
<h3 id="简述SparkSQL中RDD-DataFrame-DataSet三者的区别与联系"><a href="#简述SparkSQL中RDD-DataFrame-DataSet三者的区别与联系" class="headerlink" title="简述SparkSQL中RDD DataFrame DataSet三者的区别与联系"></a>简述SparkSQL中RDD DataFrame DataSet三者的区别与联系</h3><ol>
<li><p>RDD<br>优点: 编译时类型安全，编译时能检查出类型错误，面向对象的编程风格，直接通过类点名的方式来操作数据<br>缺点: 序列化和反序列化的性能开销<br>无论是集群间的通信，还是IO操作都需要对对象的结构和数据进行序列化和反序列化<br>GC的性能开销，频繁的创建和销毁对象，势必会增加GC</p>
</li>
<li><p>DataFrame<br>DataFrame引入了schema和off-heap<br>schema: RDD每一行的数据，结构都是一样的，这个结构就存储在schema中，Spark通过schema就能够读懂数据，因此在通信和IO时就只需要序列化和反序列化数据，而结构的部分就可以省略了</p>
</li>
<li><p>DataSet<br>DataSet结合RDD和DataFrame的优点，并带来的一个新的概念Encoder<br>当序列化数据时，Encoder产生字节码与off-heap进行交互，能够达到按需访问数据的效果，而不用反序列化整个对象。Spark还没有提供自定义Encoder的API，但是未来会加入。</p>
</li>
</ol>
<!-- TODO 三者之间的转换 -->



<h3 id="当Spark涉及到数据库的操作时，如何减少运行中的数据库连接数"><a href="#当Spark涉及到数据库的操作时，如何减少运行中的数据库连接数" class="headerlink" title="当Spark涉及到数据库的操作时，如何减少运行中的数据库连接数"></a>当Spark涉及到数据库的操作时，如何减少运行中的数据库连接数</h3><p>使用foreachPartition代替foreach，在foreachPartition内获取数据库的连接</p>
<h3 id="SparkSQL中join操作和left-join操作的区别"><a href="#SparkSQL中join操作和left-join操作的区别" class="headerlink" title="SparkSQL中join操作和left join操作的区别"></a>SparkSQL中join操作和left join操作的区别</h3><h3 id="SparkStreaming有哪几种方式消费Kafka中的数据，他们之间的区别是什么"><a href="#SparkStreaming有哪几种方式消费Kafka中的数据，他们之间的区别是什么" class="headerlink" title="SparkStreaming有哪几种方式消费Kafka中的数据，他们之间的区别是什么"></a>SparkStreaming有哪几种方式消费Kafka中的数据，他们之间的区别是什么</h3><h3 id="简述SparkStreaming窗口函数的原理"><a href="#简述SparkStreaming窗口函数的原理" class="headerlink" title="简述SparkStreaming窗口函数的原理"></a>简述SparkStreaming窗口函数的原理</h3><p>窗口函数就是在原来定义的SparkStreaming计算批次大小的基础上再次进行封装，每次计算多个批次的数据，同时还需要传递一个滑动步长的参数，用来设置当次计算任务完成之后下一次从什么地方开始计算</p>
<h3 id="手写WordCount的Spark实现"><a href="#手写WordCount的Spark实现" class="headerlink" title="手写WordCount的Spark实现"></a>手写WordCount的Spark实现</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> conf: <span class="type">SparkConf</span> = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"WordCount"</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">sc.textFile(<span class="string">"/input"</span>)</span><br><span class="line">    .flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    .map((_,<span class="number">1</span>))</span><br><span class="line">    .reduceByKey(_+_)</span><br><span class="line">    .saveAsTextFile(<span class="string">"/output"</span>)</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure>

<h3 id="如何使用Spark实现TopN的获取-描述思路或使用伪代码"><a href="#如何使用Spark实现TopN的获取-描述思路或使用伪代码" class="headerlink" title="如何使用Spark实现TopN的获取(描述思路或使用伪代码)"></a>如何使用Spark实现TopN的获取(描述思路或使用伪代码)</h3><p><strong>方法一</strong></p>
<ol>
<li>按照key对数据进行聚合(groupByKey)</li>
<li>将value转换成数组，利用scala的sortBy或者sortWith进行排序(mapValues)数据量太大，会OOM</li>
</ol>
<p><strong>方法二</strong></p>
<ol>
<li>取出所有的key</li>
<li>对key进行迭代，每次取出一个key利用spark的排序算子进行排序</li>
</ol>
<p><strong>方案三</strong></p>
<ol>
<li>自定义分区器，按照key进行分区，是不同的key进到不同的分区</li>
<li>对每个分区运用spark的排序算子进行排序</li>
</ol>
<h3 id="调优之前和调优之后性能的详细对比"><a href="#调优之前和调优之后性能的详细对比" class="headerlink" title="调优之前和调优之后性能的详细对比"></a>调优之前和调优之后性能的详细对比</h3><p>对于几百个文件，相应的有几百个map，读取数据之后进行join操作，会非常的慢，这个时候使用coalesce操作，比如240个map，我们合成60个map，也就是宽依赖。这样再shuffle，过程产生的文件数会大大减少，从而提高join的性能</p>
<h1 id="Spark-Sql-DataFrames-DataSet"><a href="#Spark-Sql-DataFrames-DataSet" class="headerlink" title="Spark Sql, DataFrames, DataSet"></a>Spark Sql, DataFrames, DataSet</h1><h3 id="append和overwrite的区别"><a href="#append和overwrite的区别" class="headerlink" title="append和overwrite的区别"></a>append和overwrite的区别</h3><p>append再原有分区上进行追加，overwrite在原有分区上进行全量刷新</p>
<h3 id="cache缓存级别"><a href="#cache缓存级别" class="headerlink" title="cache缓存级别"></a>cache缓存级别</h3><p>DataFrame的cache默认采用MEMORY_AND_DISK这和RDD的默认方式不一样RDD cache默认采用MEMORY_ONLY</p>
<h3 id="释放缓存和缓存"><a href="#释放缓存和缓存" class="headerlink" title="释放缓存和缓存"></a>释放缓存和缓存</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 缓存</span></span><br><span class="line">dataFrame.cache</span><br><span class="line">sparkSession.catalog.cacheTable(<span class="string">"tableName"</span>)</span><br><span class="line"><span class="comment">// 释放缓存</span></span><br><span class="line">dataFrame.unpersist</span><br><span class="line">sparkSession.catalog.uncacheTable(<span class="string">"tableName"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Spark-Shuffle默认并行度"><a href="#Spark-Shuffle默认并行度" class="headerlink" title="Spark Shuffle默认并行度"></a>Spark Shuffle默认并行度</h3><p>参数<code>spark.sql.shuffle.partitions</code>决定，默认并行度为200</p>
<h3 id="Kryo序列化"><a href="#Kryo序列化" class="headerlink" title="Kryo序列化"></a>Kryo序列化</h3><p>kryo序列化比java序列化更快更紧凑，但spark默认的序列化是java而不是kryo，因为spark不支持所有序列化类型，在需要时进行注册，注册只针对于RDD，DF和DS自动实现了kryo</p>
<h3 id="BroadCast-Join"><a href="#BroadCast-Join" class="headerlink" title="BroadCast Join"></a>BroadCast Join</h3><p>先将小表数据查询出来聚合到driver端，再广播到各个executor端，使表与表join时进行本地join，避免进行网络传输产生shuffle<br>使用场景:大表join小表，只能广播小表</p>
<h3 id="控制Spark-reduce缓存-调优shuffle"><a href="#控制Spark-reduce缓存-调优shuffle" class="headerlink" title="控制Spark reduce缓存 调优shuffle"></a>控制Spark reduce缓存 调优shuffle</h3><p><code>spark.reducer.maxSizeInFilght</code>此参数为reduce task能够拉取多少数据量的一个参数默认48M，当集群资源足够时，增大此参数可减少reduce拉取数据量的次数，从而达到优化shuffle的效果，一般调大96MB，资源够大可继续往上调<br><code>spark.shuffle.file.buffer</code>此参数为每个shuffle文件输出流的内存缓冲区大小，调大此参数可以减少在创建shuffle文件时进行磁盘搜索和系统调用的次数，默认参数为32k，一般调大为64k</p>
<h3 id="注册UDF函数"><a href="#注册UDF函数" class="headerlink" title="注册UDF函数"></a>注册UDF函数</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">SparkSession</span>.udf.register</span><br></pre></td></tr></table></figure>

<h1 id="SparkStreaming"><a href="#SparkStreaming" class="headerlink" title="SparkStreaming"></a>SparkStreaming</h1><h3 id="Spark-Streaming第一次运行不丢失数据"><a href="#Spark-Streaming第一次运行不丢失数据" class="headerlink" title="Spark Streaming第一次运行不丢失数据"></a>Spark Streaming第一次运行不丢失数据</h3><p>kafka参数<code>auto.offset.reset</code>参数设置成earliest从最初始偏移量开始消费数据</p>
<h3 id="Spark-Streaming精准一次消费"><a href="#Spark-Streaming精准一次消费" class="headerlink" title="Spark Streaming精准一次消费"></a>Spark Streaming精准一次消费</h3><ol>
<li>手动维护偏移量offset</li>
<li>处理完业务数据后再进行提交偏移量操作</li>
</ol>
<p>极端情况下，如在提交偏移量时断网或停电会造成spark程序第二次启动时重复消费问题，所以在涉及到金额和精确计算的场景需要使用事务保证一次消费</p>
<h3 id="Spark-Streaming控制每秒消费数据的速度"><a href="#Spark-Streaming控制每秒消费数据的速度" class="headerlink" title="Spark Streaming控制每秒消费数据的速度"></a>Spark Streaming控制每秒消费数据的速度</h3><p>通过<code>spark.streaming.kafka.maxRatePerPartition</code>参数来设置Spark Streaming从kafka分区每秒拉取的条数</p>
<h3 id="Spark-Streaming背压机制"><a href="#Spark-Streaming背压机制" class="headerlink" title="Spark Streaming背压机制"></a>Spark Streaming背压机制</h3><p>把<code>spark.streaming.backpressure.enable</code>参数设置为true，开启背压机制后Spark Streaming会根据延迟动态去kafka消费数据，上限由<code>spark.streaming.kafka.maxRatePerPartition</code>参数控制，所以两个参数一般会一起使用</p>
<h3 id="Spark-Streaming一个stage耗时"><a href="#Spark-Streaming一个stage耗时" class="headerlink" title="Spark Streaming一个stage耗时"></a>Spark Streaming一个stage耗时</h3><p>Spark Streaming stage耗时由最慢的task决定，所以根据倾斜时某个task运行慢会导致整个Spark Streaming都运行非常慢</p>
<h3 id="Spark-Streaming优雅关闭"><a href="#Spark-Streaming优雅关闭" class="headerlink" title="Spark Streaming优雅关闭"></a>Spark Streaming优雅关闭</h3><p>把<code>spark.streaming.stopGracefullyOnShutdown</code>参数设置成true，Spark会在JVM关闭时正常关闭StreamingContext，而不是立马关闭<br>或者使用命令<code>yarn application -kill {applicationid}</code></p>
<h3 id="Spark-Streaming默认分区个数"><a href="#Spark-Streaming默认分区个数" class="headerlink" title="Spark Streaming默认分区个数"></a>Spark Streaming默认分区个数</h3><p>Spark Streaming默认分区个数和所对接的kafka topic分区个数一致，Spark Streaming里一般不会使用repartition算子增大分区，因为repartition会进行shuffle增加耗时</p>
<h1 id="元数据管理-Atlas血缘系统"><a href="#元数据管理-Atlas血缘系统" class="headerlink" title="元数据管理(Atlas血缘系统)"></a>元数据管理(Atlas血缘系统)</h1><p><a href="https://www.cnblogs.com/mantoudev/p/9986408.html" target="_blank" rel="noopener">https://www.cnblogs.com/mantoudev/p/9986408.html</a></p>
<h1 id="数据质量监控-Griffin"><a href="#数据质量监控-Griffin" class="headerlink" title="数据质量监控(Griffin)"></a>数据质量监控(Griffin)</h1><p><a href="https://blog.csdn.net/An342647823/article/details/86543432" target="_blank" rel="noopener">https://blog.csdn.net/An342647823/article/details/86543432</a></p>
<h1 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h1><h3 id="应用架构"><a href="#应用架构" class="headerlink" title="应用架构"></a>应用架构</h3><p>公司中怎么提交实时任务，有多少Job Manager</p>
<ol>
<li>我们使用yarn session模式提交任务，每次提交会创建一个新的Flink集群，为每一个job提供一个yarn-session，任务之间互相独立，互不影响，方便管理。任务执行完成之后创建的集群也会消失，线上脚本命令如下<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/yarn-session.sh -n 7 -s 8 -tm 32768 -qu root.*.* -nm *-* -d</span><br></pre></td></tr></table></figure>
其中申请7个taskManager，每个8核，每个taskmanager有32867M内存</li>
<li>集群默认只有一个Job Manager，但为了防止单点故障，我们配置了高可用。我们公司一般配置一个主Job Manager，两个备用Job Manager，然后结合Zookeeper的使用，来达到高可用</li>
</ol>
<h3 id="压测和监控"><a href="#压测和监控" class="headerlink" title="压测和监控"></a>压测和监控</h3><p>一般碰到的压力来自以下几个方面</p>
<ol>
<li>产生数据流的速度如果过快，而下游的算子消费不过来的haunted，会产生背压。背压的监控可以使用Flink Web UI(Port 8081)来可视化监控，一旦报警就能知道。一般情况下背压问题的产生可能是由于sink这个操作符没有优化好，做一下优化就可以了。如写入到ES，可以改成批量写入，可以调大ES队列的大小等</li>
<li>设置watermark的最大延迟时间这个参数，如果设置的过大，可能会造成内存的压力。可以设置最大延迟时间小一些，然后把迟到元素发送到侧输出流中去，晚一点更新结果，或者使用类似于RocksDB这样的状态后端，RocksDB会开辟堆外内存空间，但是IO速度会变慢，需要权衡</li>
<li>还有就是滑动窗口的长度如果过长，而滑动距离很短的话，Flink的性能会下降的很厉害。可以通过时间分片的方法，将每个元素只存入一个”重叠窗口”，这样就可以减少窗口中状态的写入，参考 <a href="https://www.infoq.cn/article/sIhs_qY6HCpMQNblTI9M" target="_blank" rel="noopener">https://www.infoq.cn/article/sIhs_qY6HCpMQNblTI9M</a></li>
<li>状态后端使用RocksDB，还没有碰到被撑爆的问题。</li>
</ol>
<h3 id="为什么使用Flink"><a href="#为什么使用Flink" class="headerlink" title="为什么使用Flink"></a>为什么使用Flink</h3><p>Flink的延迟低、高吞吐量和对流式数据应用场景更好的支持；另外，flink可以很好地处理乱序数据，而且可以保证exactly-once的状态一致性。</p>
<!-- TODO 文档第一章有详细对比 -->

<h3 id="checkpoint的存储"><a href="#checkpoint的存储" class="headerlink" title="checkpoint的存储"></a>checkpoint的存储</h3><p>Flink的checkpoint存储在内存或者文件系统，或者RocksDB</p>
<h3 id="exactly-once的保证"><a href="#exactly-once的保证" class="headerlink" title="exactly-once的保证"></a>exactly-once的保证</h3><p>如果下级存储不支持事务，Flink怎么保证exactly-once<br>端到端exactly-once对sink要求比较高，具体实现主要有幂等写入和事务性写入两种方式。幂等写入的场景依赖于业务逻辑，更常见的是用事务性写入。而事务性写入又有预写日志(WAL)和两阶段提交(2PC)两种方式<br>如果外部系统不支持事务，那么可以用预写日志的方式，把结果数据先当成状态保存，然后收到checkpoint完成的通知时，一次性写入sink系统</p>
<!-- TODO 文档9.2 9.3 课件-Flink的状态一致性 -->

<h3 id="状态机制"><a href="#状态机制" class="headerlink" title="状态机制"></a>状态机制</h3><p>Flink内置的很多算子，包括源source，数据存储sink都是有状态的。在Flink中，状态时钟特定算子相关联。Flink会以checkpoint的形式对各个任务的状态进行快照，用于保证故障恢复时的状态一致性。Flink通过状态后端管理状态和checkpoint的存储，状态后端可以有不同的配置选择</p>
<!-- TODO 文档第九章 -->

<h3 id="海量key去重"><a href="#海量key去重" class="headerlink" title="海量key去重"></a>海量key去重</h3><p>如实际场景:双十一时，滑动窗口长度是要1个小时，滑动距离为10秒钟，亿级用户，如何计算UV<br>使用scala的set数据结构或者redis的set显然不行，因为可能有上亿个key，内存放不下，所以可以考虑是使用布隆过滤器(Bloom Filter)来去重</p>
<h3 id="checkpoint与spark的比较"><a href="#checkpoint与spark的比较" class="headerlink" title="checkpoint与spark的比较"></a>checkpoint与spark的比较</h3><p>spark streaming的checkpoint仅仅是针对driver的故障恢复做了数据和元数据的checkpoint，而flink的checkpoint机制要复杂了很多，它采用的是轻量级的分布式快照，实现了每个算子的快照，及流动中的数据的快照<br>参考 <a href="https://cloud.tencent.com/developer/article/1189624" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1189624</a> </p>
<!-- TODO 文档9.3 -->

<h3 id="watermark机制"><a href="#watermark机制" class="headerlink" title="watermark机制"></a>watermark机制</h3><p>Watermark本质是Flink中衡量EventTime进展的一个机制，主要用来处理乱序数据</p>
<!-- TODO 文档1.3 -->

<h3 id="exactly-once如何实现"><a href="#exactly-once如何实现" class="headerlink" title="exactly-once如何实现"></a>exactly-once如何实现</h3><p>Flink依靠checkpoint机制来实现exactly-once语义，如果要实现端到端的exactly-once，还需要外部source和sink满足一定的条件。状态的存储通过状态后端来管理，Flink中可以配置不同的状态后端</p>
<!-- TODO 文档9.2 9.3 9.4 -->

<h3 id="CEP编程中，当状态没有到达的时候会将数据保存在哪里"><a href="#CEP编程中，当状态没有到达的时候会将数据保存在哪里" class="headerlink" title="CEP编程中，当状态没有到达的时候会将数据保存在哪里"></a>CEP编程中，当状态没有到达的时候会将数据保存在哪里</h3><p>在流式处理中，CEP要支持EventTime，相对应的也要支持数据的迟到现象，也就是watermark的处理逻辑。CEP对未匹配成功的事件序列的处理，和迟到数据是类似的。在Flink CEP的处理逻辑中，状态没有满足的和迟到的数据，都会存储在一个map数据结构中，也就是说，如果我们限定判断事件序列的时长为5分钟，那么内存中就会存储5分钟的数据，这在我看来，也是对内存的极大损伤之一。</p>
<h3 id="时间语义"><a href="#时间语义" class="headerlink" title="时间语义"></a>时间语义</h3><p><strong>Event Time</strong> 这是实际应用最常见的时间语义 <!-- TODO 摘抄文档第七章 --><br><strong>Processing Time</strong> 没有事件时间的情况下，或者对实时性要求超高的情况下<br><strong>Ingestion Time</strong> 存在多个Source Operator的情况下，每个Source Operator可以使用自己本地系统时钟指派Ingestion Time，后续基于时间相关的各种操作，都会使用数据记录中的Ingestion Time</p>
<h3 id="数据高峰的处理"><a href="#数据高峰的处理" class="headerlink" title="数据高峰的处理"></a>数据高峰的处理</h3><p>使用容量的kafka把数据先放到消息队列里面作为数据源，在使用Flink进行消费，不过这样会影响到一点实时性</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Tiankx</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://tiankx1003.github.io/2020/06/25/Interview--%E9%A1%B9%E7%9B%AE%E6%8A%80%E6%9C%AF/">http://tiankx1003.github.io/2020/06/25/Interview--%E9%A1%B9%E7%9B%AE%E6%8A%80%E6%9C%AF/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://tiankx1003.github.io">Tiankx</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/BigData/">BigData</a><a class="post-meta__tags" href="/tags/Interview/">Interview</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/aliPay.jpg"><div class="post-qr-code__desc">支付宝打赏</div></div><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/WeChatPay.jpg"><div class="post-qr-code__desc">微信打赏</div></div></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/06/25/HexoBuild/"><i class="fa fa-chevron-left">  </i><span>Hexo搭建个人博客</span></a></div><div class="next-post pull-right"><a href="/2020/06/25/Flink--%E7%8A%B6%E6%80%81%E4%B8%80%E8%87%B4%E6%80%A7/"><span>Flink--状态一致性</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '92790026f331d18e4b34',
  clientSecret: '178a65c6e00605cff8e87083ee818aa41cfdf013',
  repo: 'tiankx1003.github.io',
  owner: 'tiankx1003',
  admin: 'tiankx1003',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(/img/bg.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2012 - 2020 By Tiankx</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://github.com/Tianxk1003" target="_blank" rel="noopener">blog</a>!</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>